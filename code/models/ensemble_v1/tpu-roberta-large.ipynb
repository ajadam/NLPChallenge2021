{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "\n",
    "transformers.set_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n",
    "    \"\"\"\n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    tokenizer.enable_padding(max_length=maxlen)\n",
    "    all_ids = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
    "        text_chunk = texts[i:i+chunk_size].tolist()\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "    return np.array(all_ids)\n",
    "\n",
    "def regular_encode(texts, tokenizer, maxlen=512):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts, \n",
    "        return_attention_masks=False, \n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,# à changer en fonction du modèle\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    \n",
    "    return np.array(enc_di['input_ids'])\n",
    "\n",
    "def build_model(transformer, max_len=512):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(28, activation='softmax')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(Adam(lr=1.5e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_model():\n",
    "#  model = TFRobertaForSequenceClassification.from_pretrained('roberta-large', num_labels=28)\n",
    "#  model.compile(optimizer=tf.keras.optimizers.Adam(1.5e-5), \n",
    "#              loss=model.compute_loss, \n",
    "#              metrics=['accuracy'])\n",
    "#  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPU config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Data access\n",
    "PATH = '../input/nlpchallenge/'\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "MAX_LEN = 192\n",
    "MODEL = 'roberta-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fast tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c695455fa74ac4bc3051e86b6c8bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a2c736a3df4de59c4aa689aff30ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ed52af80d04063ad491c6e4ef76397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First load the real tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load text data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(PATH+'train.json').set_index('Id').loc[:, 'description']\n",
    "labels = pd.read_csv(PATH+'train_label.csv', index_col=0).loc[:, 'Category'].astype('category').cat.codes\n",
    "test_texts = pd.read_json(PATH+'test.json').set_index('Id').loc[:, 'description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text, data_label = df.tolist(), labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 2.98 s, total: 3min 24s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "x_train = regular_encode(data_text, tokenizer, maxlen=MAX_LEN)\n",
    "x_test = regular_encode(test_texts, tokenizer, maxlen=MAX_LEN)\n",
    "\n",
    "y_train = data_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datasets objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 997 ms, total: 2.3 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_train, y_train))\n",
    "    .repeat()\n",
    "    .shuffle(300000, seed=5)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(x_test)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model into the TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5335c90e0631412ab1dfc5e5952d69e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1634375628.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 192)]             0         \n",
      "_________________________________________________________________\n",
      "tf_roberta_model (TFRobertaM ((None, 192, 1024), (None 355359744 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 1024)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 355,388,444\n",
      "Trainable params: 355,388,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 1min 9s, sys: 17.6 s, total: 1min 26s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "    model = build_model(transformer_layer, max_len=MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class prediction_history(Callback):\n",
    "    def __init__(self):\n",
    "        self.predhis = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.predhis.append(model.predict(test_dataset, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "425/425 [==============================] - 68s 161ms/step\n",
      "1696/1696 [==============================] - 763s 450ms/step - accuracy: 0.8237 - loss: 0.6007\n",
      "Epoch 2/5\n",
      "425/425 [==============================] - 49s 116ms/step\n",
      "1696/1696 [==============================] - 704s 415ms/step - accuracy: 0.8742 - loss: 0.4122\n",
      "Epoch 3/5\n",
      "425/425 [==============================] - 49s 116ms/step\n",
      "1696/1696 [==============================] - 701s 413ms/step - accuracy: 0.8841 - loss: 0.3727\n",
      "Epoch 4/5\n",
      "425/425 [==============================] - 50s 117ms/step\n",
      "1696/1696 [==============================] - 706s 416ms/step - accuracy: 0.9068 - loss: 0.2967\n",
      "Epoch 5/5\n",
      "425/425 [==============================] - 50s 117ms/step\n",
      "1696/1696 [==============================] - 704s 415ms/step - accuracy: 0.9250 - loss: 0.2367\n"
     ]
    }
   ],
   "source": [
    "callbacks = [prediction_history()]\n",
    "\n",
    "n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    epochs=5,\n",
    "    callbacks = callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "#train_history = model.fit(\n",
    "#    train_dataset,\n",
    "#    steps_per_epoch=n_steps,\n",
    "#    epochs=1\n",
    "#    )\n",
    "#y_prob_somme = model.predict(test_dataset, verbose=1)\n",
    "#for i in range(4):\n",
    "#    n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "#    train_history = model.fit(\n",
    "#        train_dataset,\n",
    "#        steps_per_epoch=n_steps,\n",
    "#        epochs=1\n",
    "#    )\n",
    "#    y_prob = model.predict(test_dataset, verbose=1)\n",
    "#    y_prob_somme = y_prob_somme + y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_somme = sum(callbacks[0].predhis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('roberta-large-sub-125.npy', 'wb') as f:\n",
    "    np.save(f, y_prob_somme)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
