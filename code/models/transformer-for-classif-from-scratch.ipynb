{"cells":[{"metadata":{},"cell_type":"markdown","source":"## From https://keras.io/examples/nlp/text_classification_with_transformer/"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/challenge2021')\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\n\nfrom keras_transformers import MultiHeadSelfAttention, TransformerBlock, TokenAndPositionEmbedding\n\nfrom sklearn.utils.class_weight import compute_class_weight","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainval = keras.preprocessing.text_dataset_from_directory(\n    '../input/challenge2021/train/train',\n    batch_size=8,\n    validation_split=0.25,\n    subset=\"training\",\n    seed=1234\n)\ntest = keras.preprocessing.text_dataset_from_directory(\n    '../input/challenge2021/train/train',\n    batch_size=8,\n    validation_split=0.25,\n    subset=\"validation\",\n    seed=1234\n)\nprint(\n    \"Number of batches in trainval: %d\"\n    % tf.data.experimental.cardinality(trainval)\n)\nprint(\n    \"Number of batches in test: %d\" % tf.data.experimental.cardinality(test)\n)","execution_count":3,"outputs":[{"output_type":"stream","text":"Found 217197 files belonging to 28 classes.\nUsing 162898 files for training.\nFound 217197 files belonging to 28 classes.\nUsing 54299 files for validation.\nNumber of batches in trainval: 20363\nNumber of batches in test: 6788\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainval = trainval.shuffle(220000)\ntrain = trainval.skip(6666)\nval = trainval.take(6666)\nprint(\n    \"Number of batches in train: %d\"\n    % tf.data.experimental.cardinality(train)\n)\nprint(\n    \"Number of batches in val: %d\" % tf.data.experimental.cardinality(val)\n)","execution_count":4,"outputs":[{"output_type":"stream","text":"Number of batches in train: 13697\nNumber of batches in val: 6666\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for text_batch, label_batch in train.take(1):\n    for i in range(5):\n        print(text_batch.numpy()[i])\n        print(label_batch.numpy()[i])","execution_count":5,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-7fc4b1c5c47b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2605\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2607\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2608\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.experimental.preprocessing import TextVectorization\n\n# Model constants.\nmax_features = 20000\nembedding_dim = 128\nsequence_length = 500\n\nvectorize_layer = TextVectorization(\n    standardize='lower_and_strip_punctuation',\n    max_tokens=max_features,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's make a text-only dataset (no labels):\ntext_ds = train.map(lambda x, y: x)\n# Let's call `adapt`:\nvectorize_layer.adapt(text_ds)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vectorize_text(text, label):\n    text = tf.expand_dims(text, -1)\n    return vectorize_layer(text), label\n\n# Vectorize the data.\ntrain_ds = train.map(vectorize_text)\nval_ds = val.map(vectorize_text)\ntest_ds = test.map(vectorize_text)\n\n# Do async prefetching / buffering of the data for best performance on GPU.\ntrain_ds = train_ds.cache().prefetch(buffer_size=10)\nval_ds = val_ds.cache().prefetch(buffer_size=10)\ntest_ds = test_ds.cache().prefetch(buffer_size=10)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers, regularizers\nembed_dim = 32  # Embedding size for each token\nnum_heads = 2  # Number of attention heads\nff_dim = 32  # Hidden layer size in feed forward network inside transformer\n\ninputs = layers.Input(shape=(sequence_length,))\nembedding_layer = TokenAndPositionEmbedding(sequence_length, max_features, embed_dim)\nx = embedding_layer(inputs)\ntransformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\nx = transformer_block(x)\nx = layers.GlobalAveragePooling1D()(x)\nx = layers.Dropout(0.1)(x)\nx = layers.Dense(20, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001))(x)\nx = layers.Dropout(0.1)(x)\noutputs = layers.Dense(28, activation=\"softmax\", kernel_regularizer=regularizers.l2(0.001))(x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)\nmodel.summary()","execution_count":22,"outputs":[{"output_type":"stream","text":"Model: \"functional_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 500)]             0         \n_________________________________________________________________\ntoken_and_position_embedding (None, 500, 32)           656000    \n_________________________________________________________________\ntransformer_block_3 (Transfo (None, 500, 32)           6464      \n_________________________________________________________________\nglobal_average_pooling1d_3 ( (None, 32)                0         \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 32)                0         \n_________________________________________________________________\ndense_28 (Dense)             (None, 20)                660       \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 20)                0         \n_________________________________________________________________\ndense_29 (Dense)             (None, 28)                588       \n=================================================================\nTotal params: 663,712\nTrainable params: 663,712\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True), \n             keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=1e-5)]\nmodel.compile(\"adam\", \n              \"sparse_categorical_crossentropy\", \n              metrics=[\"accuracy\"])\nhistory = model.fit(\n    train_ds, epochs=10, validation_data=val_ds, callbacks=callbacks)","execution_count":23,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n13697/13697 [==============================] - 222s 16ms/step - loss: 1.1550 - accuracy: 0.7009 - val_loss: 0.7781 - val_accuracy: 0.7952\nEpoch 2/10\n13697/13697 [==============================] - 227s 17ms/step - loss: 0.8172 - accuracy: 0.7864 - val_loss: 0.6676 - val_accuracy: 0.8220\nEpoch 3/10\n13697/13697 [==============================] - 229s 17ms/step - loss: 0.6951 - accuracy: 0.8170 - val_loss: 0.6268 - val_accuracy: 0.8354\nEpoch 4/10\n13697/13697 [==============================] - 236s 17ms/step - loss: 0.6088 - accuracy: 0.8399 - val_loss: 0.5989 - val_accuracy: 0.8447\nEpoch 5/10\n13697/13697 [==============================] - 228s 17ms/step - loss: 0.5411 - accuracy: 0.8592 - val_loss: 0.6052 - val_accuracy: 0.8506\nEpoch 6/10\n13697/13697 [==============================] - 227s 17ms/step - loss: 0.4150 - accuracy: 0.8935 - val_loss: 0.5825 - val_accuracy: 0.8674\nEpoch 7/10\n13697/13697 [==============================] - 229s 17ms/step - loss: 0.3808 - accuracy: 0.9045 - val_loss: 0.5888 - val_accuracy: 0.8707\nEpoch 8/10\n13697/13697 [==============================] - 228s 17ms/step - loss: 0.3501 - accuracy: 0.9132 - val_loss: 0.5855 - val_accuracy: 0.8744\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred = model.predict(test_ds)\ny_pred = tf.argmax(y_pred, axis=1).numpy()\ny_pred","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"array([13, 11, 24, ...,  3, 11, 15])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = np.concatenate([y for x, y in test_ds], axis=0)\ny_true","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"array([13, 11, 24, ...,  3, 11, 15], dtype=int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_true, y_pred))","execution_count":26,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.51      0.53      0.52       346\n           1       0.65      0.70      0.67      1042\n           2       0.75      0.47      0.58       212\n           3       0.69      0.68      0.69      2927\n           4       0.75      0.58      0.65       424\n           5       0.67      0.54      0.60      1003\n           6       0.84      0.81      0.83      3174\n           7       0.67      0.70      0.68      1142\n           8       0.89      0.93      0.91      1319\n           9       0.71      0.61      0.66       358\n          10       0.77      0.66      0.71      1066\n          11       0.86      0.86      0.86     17460\n          12       0.66      0.68      0.67       220\n          13       0.78      0.83      0.80      3642\n          14       0.53      0.61      0.56       183\n          15       0.69      0.71      0.70      2536\n          16       0.70      0.47      0.56       256\n          17       0.56      0.62      0.59      1400\n          18       0.76      0.76      0.76       893\n          19       0.83      0.85      0.84      4811\n          20       0.81      0.78      0.79       555\n          21       0.51      0.53      0.52      2258\n          22       0.40      0.56      0.46       172\n          23       0.72      0.72      0.72      1163\n          24       0.67      0.68      0.67      3090\n          25       0.58      0.39      0.47       212\n          26       0.73      0.72      0.73      1651\n          27       0.71      0.65      0.68       784\n\n    accuracy                           0.77     54299\n   macro avg       0.69      0.67      0.67     54299\nweighted avg       0.77      0.77      0.77     54299\n\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}